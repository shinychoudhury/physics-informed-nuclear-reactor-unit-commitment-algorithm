{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "808930df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages\n",
    "import cvxpy as cp\n",
    "import gurobipy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import plotly.graph_objects as go\n",
    "import matplotlib.pyplot as plt\n",
    "from tabulate import tabulate\n",
    "\n",
    "#functions necessary for UC setup \n",
    "from functions import (\n",
    "    setup_optimization_problem_for_ap1000,\n",
    "    update_kinf_and_deadtime,\n",
    "    process_results,\n",
    "    build_binary_var_table,\n",
    "    compute_curtailment\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67a6e5f5-3b2c-4382-a48b-dd4c13c26962",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "\"\"\"[DO NOT CHANGE THIS]\"\"\"\n",
    "#This cell is tagged as a 'parameter' so that papermill can override the values and run this notebook\n",
    "\n",
    "n = 0\n",
    "nuclear_unit = 0\n",
    "commit_at_len_T= {}\n",
    "D_points={}\n",
    "remaining_downtime = {} \n",
    "kinfTable_udt= {}\n",
    "first_run = True\n",
    "model_name= ''\n",
    "load_percentage = 0\n",
    "PHS_percentage = 0\n",
    "PHS_duration= 0\n",
    "net_cap = 0\n",
    "horizon = 0\n",
    "pmin = 0\n",
    "VRE_percentage = 0\n",
    "cost_frac=0\n",
    "mAP1000=0\n",
    "mAP300=0\n",
    "mAP100=0\n",
    "\n",
    "Wind_Cap=0\n",
    "Solar_Cap=0\n",
    "Nuclear_Cap=0\n",
    "PHS_Cap=0\n",
    "refuel_span=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4b69b44d-5689-467c-8a91-f3be55135b09",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\"\"\"IMPORT DATA AND ROLLING DATAFRAMES\"\"\"\n",
    "\n",
    "# Convert passed dictionaries from the last run to DataFrames\n",
    "remaining_downtime = pd.DataFrame.from_dict(remaining_downtime)\n",
    "kinfTable_udt      = pd.DataFrame.from_dict(kinfTable_udt)\n",
    "commit_at_len_T    = pd.DataFrame.from_dict(commit_at_len_T)\n",
    "D_points           = pd.DataFrame.from_dict(D_points)\n",
    "\n",
    "# Current path\n",
    "path = os.getcwd()\n",
    "\n",
    "# ------------------------\n",
    "# Data import\n",
    "gen_info     = pd.read_csv(path + \"/data/Generators_data_nuclear.csv\")          # Generator info and cost assumptions\n",
    "fuels        = pd.read_csv(path + \"/data/Fuels_data.csv\")                       # Fuel costs\n",
    "gen_variable = pd.read_csv(path + \"/data/Generators_variability_nuclear.csv\")   # CF for all generators, includes geothermal\n",
    "load_yearly  = pd.read_csv(path + \"/data/ERCOT_south_load_wind_2021_2023.csv\")\n",
    "solar_wind_variablity_yearly = pd.read_csv(path + \"/data/wind_solar_variability_ERCOT.csv\")\n",
    "\n",
    "# Deadtime and Pmin from Mathematica numerics\n",
    "deadtime_matrix_ap1000 = pd.read_csv(path + \"/data/resultmatrix_ap1000.csv\")\n",
    "deadtime_matrix_ap300  = pd.read_csv(path + \"/data/resultmatrix_ap300.csv\")\n",
    "MaxReacTableAP1000     = pd.read_csv(path + \"/data/reacvspminAP1000.csv\")\n",
    "MaxReacTableAP300      = pd.read_csv(path + \"/data/reacvspminAP300.csv\")\n",
    "\n",
    "# ------------------------\n",
    "# Select the correct hour indices for the current optimization block\n",
    "T_period = range(n * 72 + 1, (n + 1) * 72 + 1)   # 3 days\n",
    "\n",
    "# Load for T_period\n",
    "loads = (\n",
    "    load_yearly[load_yearly['Hour'].isin(T_period)]\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "loads['Hour'] = range(1, 73)\n",
    "\n",
    "# Isolate wind and solar hourly CF factors for T_period\n",
    "wind_solar_T_period = (\n",
    "    solar_wind_variablity_yearly[solar_wind_variablity_yearly['Hour'].isin(T_period)]\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "hour_index = wind_solar_T_period[\"Hour\"]  # Original time periods for later use in building transposed_df\n",
    "\n",
    "# Replace wind and solar hourly CF factors in gen_variable for the current block\n",
    "gen_variable[\"WEC_SDGE_onshore_wind_turbine_1.0\"] = wind_solar_T_period[\"Wind\"]\n",
    "gen_variable[\"WEC_SDGE_solar_photovoltaic_1.0\"]   = wind_solar_T_period[\"Solar\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0bed968-b87a-4264-ad23-3b5c13399b31",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Initial processing of gen_df\"\"\"\n",
    "# (1) Rename all columns to lowercase (by convention)\n",
    "for data in [gen_info, fuels, loads, gen_variable]:\n",
    "    data.columns = data.columns.str.lower()\n",
    "\n",
    "# (2) Keep only the first 26 columns in gen_info (relevant to the UC model)\n",
    "gen_info = gen_info.iloc[:, 0:26]\n",
    "\n",
    "# (3) Merge in fuel costs and add to generator dataframe\n",
    "gen_df = (\n",
    "    gen_info\n",
    "    .merge(fuels, on=\"fuel\", how=\"outer\")\n",
    "    .sort_values(by=\"r_id\")\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "gen_df.rename({'cost_per_mmbtu': 'fuel_cost'}, axis=1, inplace=True)\n",
    "\n",
    "# (4) Add \"is_variable\" flag for variable generation sources (wind, solar)\n",
    "gen_df[\"is_variable\"] = False\n",
    "gen_df.loc[\n",
    "    gen_df[\"resource\"].isin([\"onshore_wind_turbine\", \"solar_photovoltaic\"]),\n",
    "    \"is_variable\"\n",
    "] = True\n",
    "\n",
    "# (5) Create full generator name: region + resource + cluster\n",
    "gen_df[\"gen_full\"] = (\n",
    "    gen_df[\"region\"] + \"_\" +\n",
    "    gen_df[\"resource\"] + \"_\" +\n",
    "    gen_df[\"cluster\"].astype(str)\n",
    ")\n",
    "gen_df[\"gen_full\"] = gen_df[\"gen_full\"].str.lower()\n",
    "\n",
    "#take all capacities from CEM\n",
    "gen_df.loc[gen_df['resource'] == 'onshore_wind_turbine', 'existing_cap_mw'] = int(Wind_Cap)\n",
    "gen_df.loc[gen_df['resource'] == 'solar_photovoltaic',   'existing_cap_mw'] = int(Solar_Cap)\n",
    "gen_df.loc[gen_df['resource'] == 'ap1000',   'existing_cap_mw'] = int(Nuclear_Cap)\n",
    "gen_df.loc[gen_df['resource'] == 'hydroelectric_pumped_storage',   'existing_cap_mw'] = int(PHS_Cap)\n",
    "\n",
    "# (6) Remove generators with no existing capacity\n",
    "gen_df = gen_df[gen_df[\"existing_cap_mw\"] > 0].reset_index(drop=True)\n",
    "\n",
    "# Step 1: Filter relevant resources, but exclude all existing 'ap300'\n",
    "keep_resources = ['hydroelectric_pumped_storage', 'onshore_wind_turbine', 'solar_photovoltaic']\n",
    "gen_df_filtered = gen_df[gen_df['resource'].isin(keep_resources)].copy()\n",
    "\n",
    "# Step 2: Get one representative 'ap300' row (you choose how – first, template, etc.)\n",
    "template_ap1000_row = gen_df[gen_df['resource'] == 'ap1000'].iloc[0].copy()\n",
    "\n",
    "# Step 3: Count reactors and reassign\n",
    "cap = gen_df.loc[gen_df['resource'] == 'ap1000', 'existing_cap_mw'].values[0]\n",
    "repeat_count = int(cap // 1000)\n",
    "\n",
    "# Step 4: Repeat the ap300 row\n",
    "ap1000_replicated = pd.DataFrame([template_ap1000_row] * repeat_count)\n",
    "\n",
    "# Step 5: Combine\n",
    "gen_df = pd.concat([gen_df_filtered, ap1000_replicated], ignore_index=True)\n",
    "gen_df = gen_df.assign(existing_cap_mw = np.where(gen_df[\"resource\"]==\"ap1000\", gen_df[\"existing_cap_mw\"]/repeat_count, gen_df[\"existing_cap_mw\"]))\n",
    "\n",
    "#rename 'r_id' column depending on how many generators are left\n",
    "for ii in range(gen_df.shape[0]):\n",
    "    gen_df['r_id'][ii]=ii+1\n",
    "    \n",
    "gen_df['r_id'] = gen_df['r_id'].astype(int)     #this gets built in UC.ipynb independently\n",
    "\n",
    "\n",
    "# (7) Reshape variable generation CF dataframe from wide to long format\n",
    "gen_variable_long = pd.melt(\n",
    "    gen_variable,\n",
    "    id_vars=[\"hour\"],\n",
    "    var_name='gen_full',\n",
    "    value_name='cf'\n",
    ")\n",
    "\n",
    "\"\"\"Make capacity of nuclear r_ids ZERO that have reached refueling for refuel_span\"\"\"\n",
    "\n",
    "terminate_loop_indicator=pd.read_csv(f'terminate_loop_indicator_{n}.csv', index_col=0)\n",
    "# Apply shutdown effects to gen_df and kinfTable_udt\n",
    "shutdown_idx = terminate_loop_indicator.loc[\n",
    "    terminate_loop_indicator['termination_condition'] == 1, 'r_id'\n",
    "]\n",
    "\n",
    "# Set existing_cap_mw = 0 in gen_df\n",
    "gen_df.loc[gen_df['r_id'].isin(shutdown_idx), 'existing_cap_mw'] = 0.0\n",
    "\n",
    "\n",
    "\"\"\"P_min base start\"\"\"\n",
    "if model_name == 'ap1000':\n",
    "    if pmin >= 1:\n",
    "        # Force absolute minimum for uranium units\n",
    "        gen_df.loc[gen_df['fuel'] == 'uranium', 'min_power'] = pmin\n",
    "    else:\n",
    "        # Merge p0 and update: if p0 < pmin → keep pmin; else → use p0; if p0 is NaN → keep existing\n",
    "        merged_df = gen_df.merge(kinfTable_udt[['r_id', 'p0']], on='r_id', how='left')\n",
    "        merged_df['min_power'] = np.where(\n",
    "            merged_df['p0'].notna(),\n",
    "            np.where(merged_df['p0'] < pmin, pmin, merged_df['p0']),\n",
    "            merged_df['min_power']\n",
    "        )\n",
    "        merged_df.drop(columns='p0', inplace=True)\n",
    "        gen_df = merged_df\n",
    "\n",
    "G_nuclear_critical=[]\n",
    "\n",
    "#we keep startup and shutdown cost same assuming similar startup/shutdown peocesses. We only change magnitude by multiplying with start_cost_frac\n",
    "gen_df.loc[gen_df['fuel'] == 'uranium', 'start_cost_per_mw'] *= cost_frac\n",
    "gen_df.loc[gen_df['fuel'] == 'uranium', 'shut_cost_per_mw'] *= cost_frac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "174f3235-40a5-4c87-a641-f425af1c99b5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# \"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"Set up and solve the problem\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\n",
    "#based on model_name use the appropriate function to set up optimization\n",
    "if model_name == 'ap1000':\n",
    "    result = setup_optimization_problem_for_ap1000(gen_df, loads, gen_variable_long, deadtime_matrix_ap1000,\n",
    "                                          deadtime_matrix_ap300, D_points, first_run, remaining_downtime,\\\n",
    "                                                          commit_at_len_T, PHS_duration, G_nuclear_critical)\n",
    "\n",
    "    \n",
    "# Solve the problem\n",
    "result['prob'].solve(\n",
    "    solver=cp.GUROBI,\n",
    "    verbose=True,\n",
    "    MIPGap=0.001,               # 0.1% gap target (tight but achievable)\n",
    "    TimeLimit=1000,             # Time limit in seconds (e.g., ~30 min)\n",
    "    Method=2,                   # Barrier method for root LP\n",
    "    Crossover=0,                # Skip crossover after barrier\n",
    "    Presolve=2,                 # Aggressive presolve\n",
    "    MIPFocus=1,                 # Focus on improving lower bound\n",
    "    Cuts=2,                     # Aggressive cut generation\n",
    "    Heuristics=0.1,             # Light heuristic use\n",
    "    LogFile=\"gurobi.log\"        # Save solver log to file\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecf1a4ac-3d4c-477e-8cd8-daa8db26b3b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"[SAVE RESULTS] BUILD ALL DATAFRAME IN THE DESIRED FORMAT\"\"\"\n",
    "\n",
    "#generation hourly per generator\n",
    "gen_result_df = pd.DataFrame(np.row_stack(result['GEN'].value))\n",
    "gen_result_df.index.name = 'generator'\n",
    "\n",
    "#commit hourly per generator\n",
    "commit_result_df = pd.DataFrame(np.row_stack(result['COMMIT'].value))\n",
    "commit_result_df.index.name = 'generator'\n",
    "\n",
    "#downtime hourly per generator that needs extending\n",
    "dynamic_downtime_df = pd.DataFrame(np.row_stack(result['dynamic_downtime'].value))\n",
    "dynamic_downtime_df.index.name = 'generator'\n",
    "\n",
    "\n",
    "#shutdowns hourly per generator\n",
    "shut_result_df = pd.DataFrame(np.row_stack(result['SHUT'].value))\n",
    "shut_result_df.index.name = 'generator'\n",
    "\n",
    "#startups hourly per generator\n",
    "start_result_df = pd.DataFrame(np.row_stack(result['START'].value))\n",
    "start_result_df.index.name = 'generator'\n",
    "\n",
    "#net objective value\n",
    "cost = result['prob'].value\n",
    "\n",
    "# # Calculate curtailment = available wind and/or solar output that had to be wasted due to operating constraints\n",
    "gen_result_df_long = gen_result_df.copy(deep=True)\n",
    "gen_result_df_long[\"r_id\"] = gen_df[\"r_id\"]\n",
    "gen_result_df_long = pd.melt(gen_result_df_long, id_vars=[\"r_id\"], var_name='hour', value_name='gen')\n",
    "\n",
    "#compute curtailment\n",
    "curtail = compute_curtailment(\n",
    "    gen_result_df=gen_result_df,\n",
    "    gen_df=gen_df,\n",
    "    result=result,\n",
    "    hour_from_columns=True,     # or False with hour_index=...\n",
    "    wind_tag=\"wec_sdge_onshore_wind_turbine_1.0\",\n",
    "    solar_tag=\"wec_sdge_solar_photovoltaic_1.0\",\n",
    "    wind_resource_name=\"onshore_wind_turbine\",\n",
    "    solar_resource_name=\"solar_photovoltaic\",\n",
    "    floor_zero=True\n",
    ")\n",
    "\n",
    "#PHS Results\n",
    "gen_phs = gen_result_df_long[gen_result_df_long[\"r_id\"] == 1].reset_index(drop=True)\n",
    "gen_phs[\"charge\"] = result[\"CHARGE\"].value\n",
    "gen_phs[\"discharge\"] = result[\"DISCHARGE\"].value\n",
    "gen_phs[\"soc\"]=result[\"SOC\"].value\n",
    "\n",
    "START  = build_binary_var_table(start_result_df, hour_index, \"START\", n)\n",
    "SHUT   = build_binary_var_table(shut_result_df, hour_index, \"SHUT\", n)\n",
    "GEN    = build_binary_var_table(gen_result_df, hour_index, \"GEN\", n)\n",
    "COMMIT = build_binary_var_table(commit_result_df, hour_index, \"COMMIT\", n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ed8e040-385f-4adf-b654-42cac199d49f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save commit results for analysis\n",
    "commit_result = pd.DataFrame(np.row_stack(result['COMMIT'].value))\n",
    "\n",
    "#Commit result at hour len(T)\n",
    "commit_at_len_T = pd.DataFrame()\n",
    "commit_at_len_T['commitment'] = commit_result.iloc[:, -1].round().astype(int)\n",
    "commit_at_len_T['generator'] = gen_df['r_id'].astype(int)\n",
    "commit_at_len_T['termination_condition'] = 0\n",
    "\n",
    "# Calculate the potential soc_transfer value\n",
    "potential_soc_transfer = gen_phs[\"soc\"].iloc[-1] + (gen_phs[\"charge\"].iloc[-1] * 0.84) - (gen_phs[\"discharge\"].iloc[-1] / 0.84)\n",
    "\n",
    "# Ensure soc_transfer is not negative\n",
    "commit_at_len_T['soc_transfer'] = max(0, potential_soc_transfer)\n",
    "\n",
    "\n",
    "#counts the total number of shutdowns each run\n",
    "shut_count = (result['SHUT'].value==1).sum().sum()\n",
    "start_count = (result['START'].value==1).sum().sum()\n",
    "shut_df = pd.DataFrame({'n':[n],'shut_count': [shut_count],\\\n",
    "                        'start_count': [start_count],\n",
    "                        'obj_value':[result['UCcost'].value]})\n",
    "\n",
    "G_thermal = gen_df[gen_df[\"up_time\"] > 0][\"r_id\"].tolist() #thermal generators\n",
    "remaining_downtime = pd.DataFrame(columns=['generator','remaining_downtime'])\n",
    "remaining_downtime['generator'] = G_thermal\n",
    "\n",
    "# Extract remaining downtime for next run\n",
    "T = loads[\"hour\"]\n",
    "for i in G_thermal:\n",
    "    for t in range(len(T)):\n",
    "        if shut_result_df.loc[i-1, t] == 1:\n",
    "            downtime_start = t\n",
    "            downtime_duration = dynamic_downtime_df.loc[i-1, t]  # Assuming dynamic_downtime_df is a DataFrame\n",
    "            remaining_hours_in_window = len(T) - downtime_start  # Time remaining in this optimization window\n",
    "            # Calculate remaining downtime that will carry over to the next optimization period\n",
    "            remaining_downtime_for_next_period = max(0, downtime_duration - remaining_hours_in_window)\n",
    "            remaining_downtime.loc[remaining_downtime['generator'] == i, \\\n",
    "            'remaining_downtime'] = int(remaining_downtime_for_next_period)\n",
    "\n",
    "\n",
    "# Fill NaN values with 0 (or any other value you want)\n",
    "remaining_downtime.fillna(0, inplace=True)\n",
    "remaining_downtime.reset_index(drop=True, inplace=True)\n",
    "\n",
    "\n",
    "remaining_downtime.to_csv(f'remaining_downtime_{n+1}.csv')\n",
    "shut_df.to_csv(f'shut_df_{n}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c773dcc5-0b3b-4f1f-8028-f19376e8a1af",
   "metadata": {},
   "outputs": [],
   "source": [
    "#aggregate results for post process and nect run\n",
    "gen_result_df_grouped = gen_result_df.copy(deep=True)\n",
    "gen_result_df_grouped[\"resource\"] = gen_df[\"resource\"]\n",
    "gen_result_df_grouped = gen_result_df_grouped.groupby('resource', as_index=False).sum()\n",
    "\n",
    "#inputs to process_results\n",
    "transposed_df = process_results(\n",
    "    gen_result_df_grouped, gen_phs, loads, result, curtail,\n",
    "    model_name, hour_index, n\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4e3a8f2-7e20-412c-a767-54b917891209",
   "metadata": {},
   "outputs": [],
   "source": [
    "#degrades k_eff values, updates deadtime for next runs and updates termiantion indicator\n",
    "\n",
    "kinfTable_udt, D_points, terminate_loop_indicator, commit_at_len_T = update_kinf_and_deadtime(\n",
    "    n, kinfTable_udt, gen_result_df, gen_df,\n",
    "    MaxReacTableAP1000, MaxReacTableAP300,\n",
    "    deadtime_matrix_ap1000, deadtime_matrix_ap300,\n",
    "    terminate_loop_indicator, commit_at_len_T, D_points,\n",
    "    mAP1000, mAP300, T, pmin, refuel_span\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
