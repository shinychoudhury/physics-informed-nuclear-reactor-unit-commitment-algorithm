{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "795a09a3-dfec-409d-9a3f-f6891f1c9243",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load packages\n",
    "import papermill as pm                               #to parameterize and execute across jupyter notebooks\n",
    "import pandas as pd\n",
    "import os\n",
    "from concurrent.futures import ThreadPoolExecutor    #for parallelization\n",
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "import matplotlib.pyplot as plt\n",
    "from tabulate import tabulate\n",
    "import plotly.graph_objects as go\n",
    "from datetime import datetime\n",
    "import os\n",
    "import signal\n",
    "import sys\n",
    "from datetime import datetime\n",
    "\n",
    "#custom functions\n",
    "from functions import (\n",
    "    solve_single_UC,\n",
    "    save_checkpoint,\n",
    "    init_state\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e79b52ae-1889-4ae6-a788-266cb3a87eb5",
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "file_path = ''\n",
    "subfolder_name = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5e55254a-c5f3-49b5-bba1-0a1aa8106d1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "path=os.getcwd()\n",
      "cem_results=pd.read_csv(path+'/data/CEM_results/cem_results.csv')\n",
      "Wind_Cap = int(cem_results.loc[cem_results['resource'] == 'onshore_wind_turbine', 'CAP'].iloc[0])\n",
      "Solar_Cap = int(cem_results.loc[cem_results['resource'] == 'solar_photovoltaic', 'CAP'].iloc[0])\n",
      "Nuclear_Cap = int(cem_results.loc[cem_results['resource'] == 'ap1000', 'CAP'].iloc[0])\n",
      "PHS_Cap = int(cem_results.loc[cem_results['resource'] == 'hydroelectric_pumped_storage', 'CAP'].iloc[0])\n",
      "horizon = 72        #time period of UC dispatch\n",
      "load_percentage = 1\n",
      "PHS_percentage = 0.1\n",
      "model_name = 'ap1000'\n",
      "VRE_percentage = 0.2\n",
      "mAP300 = 0.001137\n",
      "mAP100 = 0.001137\n",
      "q = 0.11\n",
      "nuclear_unit = 0\n",
      "pmin=0.8              #minimum generation percentages for nuclear reactors\n",
      "PHS_duration=4        #battery duration\n",
      "cost_frac=1           #fraction of startup/shutdown cost for nuclear. 1 means 100%\n",
      "k_init_ap1000=1.205   #initial k_eff value\n",
      "mAP1000=0.001137      # degradation rate\n",
      "start_day=0           #dispatch init period [3 day blocks]\n",
      "end_day=2             #dispatch end period  [3 day blocks]\n",
      "refuel_span=10        #span of refueling outage\n"
     ]
    }
   ],
   "source": [
    "# Path to the text file\n",
    "# file_path = 'Config.txt'\n",
    "\n",
    "# Open the file and read its contents\n",
    "with open(file_path, 'r') as file:\n",
    "    for line in file:\n",
    "        # Strip whitespace and ignore comments or empty lines\n",
    "        line = line.strip()\n",
    "        if line and not line.startswith('#'):\n",
    "            # Directly execute the line to set variables\n",
    "            exec(line)\n",
    "            print(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2f4e07a6-3158-464b-a5fb-64c041601f1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-3-d919efbcb4f3>:77: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  gen_df['r_id'][ii]=ii+1\n",
      "<ipython-input-3-d919efbcb4f3>:77: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  gen_df['r_id'][ii]=ii+1\n",
      "<ipython-input-3-d919efbcb4f3>:77: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  gen_df['r_id'][ii]=ii+1\n",
      "<ipython-input-3-d919efbcb4f3>:77: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  gen_df['r_id'][ii]=ii+1\n",
      "<ipython-input-3-d919efbcb4f3>:77: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  gen_df['r_id'][ii]=ii+1\n",
      "<ipython-input-3-d919efbcb4f3>:77: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  gen_df['r_id'][ii]=ii+1\n",
      "<ipython-input-3-d919efbcb4f3>:77: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  gen_df['r_id'][ii]=ii+1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>r_id</th>\n",
       "      <th>resource</th>\n",
       "      <th>region</th>\n",
       "      <th>existing_cap_mw</th>\n",
       "      <th>var_om_cost_per_mwh</th>\n",
       "      <th>fuel</th>\n",
       "      <th>heat_rate_mmbtu_per_mwh</th>\n",
       "      <th>min_power</th>\n",
       "      <th>ramp_up_percentage</th>\n",
       "      <th>ramp_dn_percentage</th>\n",
       "      <th>start_cost_per_mw</th>\n",
       "      <th>shut_cost_per_mw</th>\n",
       "      <th>up_time</th>\n",
       "      <th>down_time</th>\n",
       "      <th>cluster</th>\n",
       "      <th>fuel_cost</th>\n",
       "      <th>co2_content_tons_per_mmbtu</th>\n",
       "      <th>is_variable</th>\n",
       "      <th>gen_full</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>hydroelectric_pumped_storage</td>\n",
       "      <td>WEC_SDGE</td>\n",
       "      <td>6000.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>wec_sdge_hydroelectric_pumped_storage_1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>onshore_wind_turbine</td>\n",
       "      <td>WEC_SDGE</td>\n",
       "      <td>8000.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>wec_sdge_onshore_wind_turbine_1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>solar_photovoltaic</td>\n",
       "      <td>WEC_SDGE</td>\n",
       "      <td>12000.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>wec_sdge_solar_photovoltaic_1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>ap1000</td>\n",
       "      <td>WEC_SDGE</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>4.55</td>\n",
       "      <td>uranium</td>\n",
       "      <td>10.44</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>107.86</td>\n",
       "      <td>107.86</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>wec_sdge_ap1000_1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>ap1000</td>\n",
       "      <td>WEC_SDGE</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>4.55</td>\n",
       "      <td>uranium</td>\n",
       "      <td>10.44</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>107.86</td>\n",
       "      <td>107.86</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>wec_sdge_ap1000_1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>ap1000</td>\n",
       "      <td>WEC_SDGE</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>4.55</td>\n",
       "      <td>uranium</td>\n",
       "      <td>10.44</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>107.86</td>\n",
       "      <td>107.86</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>wec_sdge_ap1000_1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>ap1000</td>\n",
       "      <td>WEC_SDGE</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>4.55</td>\n",
       "      <td>uranium</td>\n",
       "      <td>10.44</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>107.86</td>\n",
       "      <td>107.86</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>wec_sdge_ap1000_1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   r_id                      resource    region  existing_cap_mw  \\\n",
       "0     1  hydroelectric_pumped_storage  WEC_SDGE           6000.0   \n",
       "1     2          onshore_wind_turbine  WEC_SDGE           8000.0   \n",
       "2     3            solar_photovoltaic  WEC_SDGE          12000.0   \n",
       "3     4                        ap1000  WEC_SDGE           1000.0   \n",
       "4     5                        ap1000  WEC_SDGE           1000.0   \n",
       "5     6                        ap1000  WEC_SDGE           1000.0   \n",
       "6     7                        ap1000  WEC_SDGE           1000.0   \n",
       "\n",
       "   var_om_cost_per_mwh     fuel  heat_rate_mmbtu_per_mwh  min_power  \\\n",
       "0                 0.00      NaN                     0.00        0.0   \n",
       "1                 0.00      NaN                     0.00        0.0   \n",
       "2                 0.00      NaN                     0.00        0.0   \n",
       "3                 4.55  uranium                    10.44        0.5   \n",
       "4                 4.55  uranium                    10.44        0.5   \n",
       "5                 4.55  uranium                    10.44        0.5   \n",
       "6                 4.55  uranium                    10.44        0.5   \n",
       "\n",
       "   ramp_up_percentage  ramp_dn_percentage  start_cost_per_mw  \\\n",
       "0                0.00                0.00               0.00   \n",
       "1                1.00                1.00               0.00   \n",
       "2                1.00                1.00               0.00   \n",
       "3                0.25                0.25             107.86   \n",
       "4                0.25                0.25             107.86   \n",
       "5                0.25                0.25             107.86   \n",
       "6                0.25                0.25             107.86   \n",
       "\n",
       "   shut_cost_per_mw  up_time  down_time  cluster  fuel_cost  \\\n",
       "0              0.00      0.0        0.0      1.0        0.0   \n",
       "1              0.00      0.0        0.0      1.0        0.0   \n",
       "2              0.00      0.0        0.0      1.0        0.0   \n",
       "3            107.86      1.0        1.0      1.0        0.5   \n",
       "4            107.86      1.0        1.0      1.0        0.5   \n",
       "5            107.86      1.0        1.0      1.0        0.5   \n",
       "6            107.86      1.0        1.0      1.0        0.5   \n",
       "\n",
       "   co2_content_tons_per_mmbtu  is_variable  \\\n",
       "0                         0.0        False   \n",
       "1                         0.0         True   \n",
       "2                         0.0         True   \n",
       "3                         0.0        False   \n",
       "4                         0.0        False   \n",
       "5                         0.0        False   \n",
       "6                         0.0        False   \n",
       "\n",
       "                                    gen_full  \n",
       "0  wec_sdge_hydroelectric_pumped_storage_1.0  \n",
       "1          wec_sdge_onshore_wind_turbine_1.0  \n",
       "2            wec_sdge_solar_photovoltaic_1.0  \n",
       "3                        wec_sdge_ap1000_1.0  \n",
       "4                        wec_sdge_ap1000_1.0  \n",
       "5                        wec_sdge_ap1000_1.0  \n",
       "6                        wec_sdge_ap1000_1.0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#path+load data+build basic gen_df\n",
    "path=os.getcwd()\n",
    "\n",
    "gen_info = pd.read_csv(path+\"/data/\"+\"Generators_data_nuclear.csv\")   #has data on cost and engineering charactristics of all the different kinds of generators \n",
    "fuels = pd.read_csv(path+\"/data/\"+\"Fuels_data.csv\") #has details on fuel costs\n",
    "gen_variable = pd.read_csv(path+\"/data/\"+\"Generators_variability_nuclear.csv\")  #CF for all generators, added geothermal\n",
    "solar_wind_variablity_yearly=pd.read_csv(path+\"/data/\"+\"wind_solar_variability_ERCOT.csv\")\n",
    "load_yearly=pd.read_csv(path+\"/data/\"+\"ERCOT_south_load_wind_2021_2023.csv\")\n",
    "load_yearly.Demand=load_yearly.Demand\n",
    "\n",
    "\n",
    "#build a temp gen_df from original generator info table for use to built init kinf table\n",
    "n=0                                            #random choice\n",
    "T_period = range(n * 24 + 1, (n + 1) * 24 + 1)    #isolate hours and other relevant data for day 'n'\n",
    "loads = load_yearly[load_yearly['Hour'].isin(T_period)].reset_index(drop=True)\n",
    "loads['Hour'] = range(1, 25)  \n",
    "\n",
    "# (1) Rename all columns to lowercase (by convention)\n",
    "for data in [gen_info, fuels, loads, gen_variable]:\n",
    "    data.columns = data.columns.str.lower()\n",
    "    \n",
    "# (2) Keep columns relevant to our UC model \n",
    "gen_info = gen_info.iloc[:, 0:26]\n",
    "\n",
    "#(3) Load in fuel costs and add to data frame\n",
    "gen_df = gen_info.merge(fuels, on=\"fuel\", how=\"outer\").sort_values(by=\"r_id\").reset_index(drop=True)\n",
    "gen_df.rename({'cost_per_mmbtu': 'fuel_cost'}, axis=1, inplace=True)\n",
    "\n",
    "#(4) Create \"is_variable\" column to indicate if this is a variable generation source (e.g. wind, solar)\n",
    "gen_df[\"is_variable\"] = False\n",
    "gen_df.loc[\n",
    "    gen_df[\"resource\"].isin([\"onshore_wind_turbine\",\"small_hydroelectric\",\"solar_photovoltaic\"]), \n",
    "    \"is_variable\"] = True\n",
    "\n",
    "#(5) Create full name of generator (including geographic location and cluster number)\n",
    "#  for use with variable generation dataframe\n",
    "gen_df[\"gen_full\"] = gen_df[\"region\"] + \"_\" + gen_df[\"resource\"] + \"_\" + gen_df[\"cluster\"].astype(str)\n",
    "gen_df[\"gen_full\"] = gen_df[\"gen_full\"].str.lower()\n",
    "\n",
    "# (6) Remove generators with no capacity (e.g. new build options that we'd use if this was capacity expansion problem)\n",
    "gen_df = gen_df[gen_df[\"existing_cap_mw\"] > 0].reset_index(drop=True)\n",
    "\n",
    "#Isolate wind and solar hourly CF factors for 'n' or 'T_period'\n",
    "wind_solar_T_period=solar_wind_variablity_yearly[solar_wind_variablity_yearly['Hour'].isin(T_period)].reset_index(drop=True)\n",
    "hour_index=wind_solar_T_period[\"Hour\"]  #to be used later in building transposed_df\n",
    "\n",
    "#replace wind and solar hourly CF factors in gen_variable\n",
    "gen_variable[\"WEC_SDGE_onshore_wind_turbine_1.0\"]=wind_solar_T_period[\"Wind\"]\n",
    "gen_variable[\"WEC_SDGE_solar_photovoltaic_1.0\"]=wind_solar_T_period[\"Solar\"]\n",
    "\n",
    "#take all capacities from CEM\n",
    "gen_df.loc[gen_df['resource'] == 'onshore_wind_turbine', 'existing_cap_mw'] = int(Wind_Cap)\n",
    "gen_df.loc[gen_df['resource'] == 'solar_photovoltaic',   'existing_cap_mw'] = int(Solar_Cap)\n",
    "gen_df.loc[gen_df['resource'] == 'ap1000',   'existing_cap_mw'] = int(Nuclear_Cap)\n",
    "gen_df.loc[gen_df['resource'] == 'hydroelectric_pumped_storage',   'existing_cap_mw'] = int(PHS_Cap)\n",
    "\n",
    "# Step 1: Filter relevant resources, but exclude all existing 'ap300'\n",
    "keep_resources = ['hydroelectric_pumped_storage', 'onshore_wind_turbine', 'solar_photovoltaic']\n",
    "gen_df_filtered = gen_df[gen_df['resource'].isin(keep_resources)].copy()\n",
    "\n",
    "# Step 2: Get one representative 'ap300' row (you choose how â€“ first, template, etc.)\n",
    "template_ap1000_row = gen_df[gen_df['resource'] == 'ap1000'].iloc[0].copy()\n",
    "\n",
    "# Step 3: Count reactors and reassign\n",
    "cap = gen_df.loc[gen_df['resource'] == 'ap1000', 'existing_cap_mw'].values[0]\n",
    "repeat_count = int(cap // 1000)\n",
    "\n",
    "# Step 4: Repeat the ap300 row\n",
    "ap1000_replicated = pd.DataFrame([template_ap1000_row] * repeat_count)\n",
    "\n",
    "# Step 5: Combine\n",
    "gen_df = pd.concat([gen_df_filtered, ap1000_replicated], ignore_index=True)\n",
    "gen_df = gen_df.assign(existing_cap_mw = np.where(gen_df[\"resource\"]==\"ap1000\", gen_df[\"existing_cap_mw\"]/repeat_count, gen_df[\"existing_cap_mw\"]))\n",
    "\n",
    "#rename 'r_id' column depending on how many generators are left\n",
    "for ii in range(gen_df.shape[0]):\n",
    "    gen_df['r_id'][ii]=ii+1\n",
    "    \n",
    "gen_df['r_id'] = gen_df['r_id'].astype(int)     #this gets built in UC.ipynb independently\n",
    "gen_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a9b52f5b-ce82-4228-99c8-11511f1d1fb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kinf_table:\n",
      "    r_id resource   keff     ReacValue   p0  alpha  nearest_k\n",
      "0     4   ap1000  1.205  17012.448133  0.8      1    1.20462\n",
      "1     5   ap1000  1.205  17012.448133  0.8      1    1.20462\n",
      "2     6   ap1000  1.205  17012.448133  0.8      1    1.20462\n",
      "3     7   ap1000  1.205  17012.448133  0.8      1    1.20462 \n",
      " \n",
      " D_points:\n",
      "    r_id  deadtime_value\n",
      "0     4               6\n",
      "1     5               6\n",
      "2     6               6\n",
      "3     7               6\n"
     ]
    }
   ],
   "source": [
    "#Initialize all reactors keff values and form a D_point and kinfTable_udt dataframe for tandem run\n",
    "#Handels \"ap1000\" or \"ap300\" based on whichever is being run\n",
    "\n",
    "MaxReacTableAP1000=pd.read_csv(path+\"/data/\"+\"reacvspminAP1000.csv\")\n",
    "MaxReacTableAP300=pd.read_csv(path+\"/data/\"+\"reacvspminAP300.csv\")\n",
    "\n",
    "deadtime_matrix_ap1000=pd.read_csv(path+\"/data/\"+\"resultmatrix_ap1000.csv\")\n",
    "deadtime_matrix_ap300=pd.read_csv(path+\"/data/\"+\"resultmatrix_ap300.csv\")\n",
    "\n",
    "\n",
    "MaxReacTableAP1000['resource'] = 'ap1000'\n",
    "MaxReacTableAP300['resource'] = 'ap300'\n",
    "\n",
    "\n",
    "MaxReacTable = pd.concat([MaxReacTableAP1000, MaxReacTableAP300], ignore_index=True)\n",
    "\n",
    "\n",
    "kinfTable=pd.DataFrame()\n",
    "G_thermal = gen_df[gen_df[\"up_time\"] > 0][\"r_id\"].tolist() # thermal\n",
    "G = gen_df[\"r_id\"].tolist()\n",
    "\n",
    "kinfTable['r_id']=G_thermal\n",
    "# kinfTable['resource']=gen_info[gen_info['r_id'].isin(G_thermal)][['resource']]\n",
    "\n",
    "kinfTable=pd.DataFrame()\n",
    "kinfTable = gen_df[gen_df['r_id'].isin(G_thermal)][['r_id', 'resource']].reset_index(drop=True).copy()\n",
    "kinfTable['keff'] = kinfTable['resource'].apply(lambda x: k_init_ap1000 if x == 'ap1000' else (k_init_ap300 if x == 'ap300' else (k_init_ap100 if x == 'ap100' else None)))\n",
    "kinfTable['ReacValue']=((kinfTable['keff']-1)/kinfTable['keff'])*(1e5)\n",
    "\n",
    "# Initialize an empty list to hold the 'p0' values\n",
    "p0_values = []\n",
    "\n",
    "# Loop through each row in 'kinfTable'\n",
    "for index, row in kinfTable.iterrows():\n",
    "    resource = row['resource']\n",
    "    reac_value = row['ReacValue']\n",
    "    # Filter 'MaxReacTable' to only include rows with the same 'resource'\n",
    "    filtered_max_reac_table = MaxReacTable[MaxReacTable['resource'] == resource]\n",
    "    \n",
    "    # Compute the positive differences between 'MaxReactivityXe' and 'ReacValue'\n",
    "    differences = reac_value - filtered_max_reac_table['MaxReactivityXe']\n",
    "    positive_differences = differences[differences >= 0]\n",
    "    \n",
    "    # Find the row in 'MaxReacTable' with the smallest positive difference\n",
    "    if not positive_differences.empty:\n",
    "        min_diff_index = positive_differences.idxmin()\n",
    "        corresponding_p0 = MaxReacTable.loc[min_diff_index, 'p0']\n",
    "    else:\n",
    "        corresponding_p0 = np.nan  # Use NaN if no such value exists\n",
    "    \n",
    "    p0_values.append(corresponding_p0)\n",
    "\n",
    "# Add the 'p0' values as a new column in 'kinfTable'\n",
    "# p0_values_clean = np.where(np.isnan(p0_values), int(1), p0_values)\n",
    "\n",
    "# kinfTable['p0'] = p0_values_clean\n",
    "kinfTable['p0'] = np.where(np.isnan(p0_values), 1, np.maximum(p0_values, pmin))\n",
    "kinfTable['alpha']=1\n",
    "\n",
    "kinfTable_udt=kinfTable.copy()\n",
    "\n",
    "# Initialize a new column 'nearest_k' in the DataFrame kinfTable_udt and fill it with NaN (Not a Number) values.\n",
    "kinfTable_udt['nearest_k'] = np.nan  \n",
    "# Initialize D_points DataFrame with 'r_id' from kinfTable_udt\n",
    "D_points = pd.DataFrame()\n",
    "D_points['r_id'] = kinfTable_udt['r_id']\n",
    "\n",
    "# Initialize columns for each of the 8 deadtime values\n",
    "for i in range(1, len(deadtime_matrix_ap1000)+1):  # Assuming 8 values\n",
    "    D_points[f'deadtime_value'] = 0\n",
    "\n",
    "# Iterate through each row of the DataFrame kinfTable_udt.\n",
    "for idx, row in kinfTable_udt.iterrows():\n",
    "    # Extract keff and resource ID for the current row.\n",
    "    keff_value = row['keff']\n",
    "    r_id_value = row['r_id']\n",
    "    resource_value = row['resource']  # Assuming the column is named 'resource'\n",
    "\n",
    "    # Choose the appropriate deadtime_matrix based on the 'resource'.\n",
    "    if resource_value == 'ap1000':\n",
    "        deadtime_matrix = deadtime_matrix_ap1000\n",
    "    elif resource_value == 'ap300':\n",
    "        deadtime_matrix = deadtime_matrix_ap300\n",
    "    else:\n",
    "        print(f\"Unknown resource: {resource_value}\")\n",
    "        continue\n",
    "\n",
    "    # Calculate the absolute differences between keff_value and each k value, rounded to 4 decimal places.\n",
    "    # k_diffs = {col: round(abs(keff_value - float(col)), 4) for col in deadtime_matrix.columns if col != 'p'}\n",
    "    k_values_less_than_keff = [float(col) for col in deadtime_matrix.columns if (col != 'p' and float(col) < keff_value)]\n",
    "        \n",
    "    # Find the k value that is the largest but still less than keff_value.\n",
    "    # Handle empty k_values_less_than_keff by finding the last value in deadtime_matrix\n",
    "    if not k_values_less_than_keff:\n",
    "        # Extract the last column value which is a float and not 'p'\n",
    "        last_column = next((col for col in reversed(deadtime_matrix.columns) if col != 'p'), None)\n",
    "        nearest_k_value = float(last_column) if last_column else float(1)  # Fallback to 1 if no valid last column found\n",
    "    else:\n",
    "        # Find the k value that is the largest but still less than keff_value.\n",
    "        nearest_k_value = max(k_values_less_than_keff)\n",
    "\n",
    "    # Update 'nearest_k' in kinfTable_udt.\n",
    "    kinfTable_udt.loc[kinfTable_udt['r_id'] == r_id_value, 'nearest_k'] = nearest_k_value\n",
    "\n",
    "    # Convert nearest_k_value to string to access the corresponding column in deadtime_matrix.\n",
    "    column_str = str(int(nearest_k_value)) if nearest_k_value.is_integer() else str(nearest_k_value)\n",
    "    deadtime_values = deadtime_matrix[column_str].tolist() \n",
    "\n",
    "    # for i, val in enumerate(deadtime_values, start=1):\n",
    "    #     D_points.loc[D_points['r_id'] == r_id_value, f'deadtime_value_{i}'] = int(val)\n",
    "    D_points.loc[D_points['r_id'] == r_id_value, 'deadtime_value'] = int(deadtime_values[0])\n",
    "\n",
    "    # for i, val in enumerate(deadtime_values, start=1):\n",
    "    #     D_points.loc[D_points['r_id'] == r_id_value, f'deadtime_value'] = int(val)\n",
    "\n",
    "\n",
    "print('kinf_table:\\n',kinfTable_udt, '\\n \\n D_points:\\n', D_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "65fafb5f-9109-4af4-9559-6edf305cc20a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Solved day -1, going to start solving for day 0 if keff of all reactors > 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bfac2aa23e9c4f9087c27e4e53c4c8e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Executing:   0%|          | 0/10 [00:00<?, ?cell/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Solved day 0, going to start solving for day 1 if keff of all reactors > 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a22cb54e4a4a4e2698cb859a81a516dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Executing:   0%|          | 0/10 [00:00<?, ?cell/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Solved day 1, going to start solving for day 2 if keff of all reactors > 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "476e3f4347484837a233a2f4311334d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Executing:   0%|          | 0/10 [00:00<?, ?cell/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished runs!\n"
     ]
    }
   ],
   "source": [
    "\"\"\"SOLVE AND SAVE intermediate results in the desired format\"\"\"\n",
    "\n",
    "# Global tracker for last completed day\n",
    "current_day = None\n",
    "\n",
    "# Directory to store rolling checkpoints\n",
    "checkpoint_dir = \"checkpoint\"\n",
    "os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "\n",
    "# Initialize all DataFrames \n",
    "state = init_state(G, G_thermal, kinfTable_udt, D_points, start_day)\n",
    "\n",
    "(master_df, GEN_df, SHUT_df, START_df, RESUP_df, RESDN_df, SLOWRES_df,\n",
    " master_shut_df, master_commit, master_kinfTable, master_commit_at_len_T,\n",
    " run_details, remaining_downtime, commit_at_len_T,\n",
    " terminate_loop_indicator, terminate_loop) = (\n",
    "    state[k] for k in [\n",
    "        \"master_df\", \"GEN_df\", \"SHUT_df\", \"START_df\", \"RESUP_df\", \"RESDN_df\", \"SLOWRES_df\",\n",
    "        \"master_shut_df\", \"master_commit\", \"master_kinfTable\", \"master_commit_at_len_T\",\n",
    "        \"run_details\", \"remaining_downtime\", \"commit_at_len_T\",\n",
    "        \"terminate_loop_indicator\", \"terminate_loop\"\n",
    "    ]\n",
    ")\n",
    "\n",
    "for n in range(start_day, end_day + 1):\n",
    "    remaining_downtime = pd.read_csv(f'remaining_downtime_{n}.csv', index_col=0)\n",
    "    commit_at_len_T = pd.read_csv(f'commit_at_len_T_{n}.csv', index_col=0)\n",
    "    kinfTable_udt = pd.read_csv(f'kinfTable_udt_{n}.csv', index_col=0)\n",
    "    D_points = pd.read_csv(f'D_points_{n}.csv', index_col=0)\n",
    "    terminate_loop_indicator = pd.read_csv(f'terminate_loop_indicator_{n}.csv', index_col=0)\n",
    "\n",
    "    print(f'Solved day {n-1}, going to start solving for day {n} if keff of all reactors > 1')\n",
    "\n",
    "    termination_status = terminate_loop_indicator\n",
    "\n",
    "    first_run = True if n == start_day else False\n",
    "\n",
    "    current_day = n\n",
    "\n",
    "    transposed_df, shut_df, remaining_downtime, commit_result, kinfTable_udt, \\\n",
    "    commit_at_len_T, D_points, GEN_result, SHUT_result, START_result = \\\n",
    "        solve_single_UC(model_name, horizon, load_percentage, PHS_percentage, PHS_duration, n, nuclear_unit,\n",
    "                        remaining_downtime, kinfTable_udt, commit_at_len_T, D_points, first_run, pmin,\n",
    "                        VRE_percentage, cost_frac, mAP1000, mAP300, mAP100, Wind_Cap, Solar_Cap, Nuclear_Cap, PHS_Cap, refuel_span)\n",
    "\n",
    "    run_data = {\n",
    "        \"Day\": int(n),\n",
    "        \"Horizon\": int(horizon),\n",
    "        \"Load Percentage\": float(load_percentage),\n",
    "        \"PHS Percentage\": float(PHS_percentage),\n",
    "        \"PHS Duration\": float(PHS_duration),\n",
    "        \"Nuclear Unit\": str(nuclear_unit),\n",
    "        \"Model Name\": str(model_name),\n",
    "        \"Solar Cap\": float(Solar_Cap),\n",
    "        \"Wind Cap\": float(Wind_Cap),\n",
    "        \"Date of Run\": datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "    }\n",
    "    run_details.append(run_data)\n",
    "\n",
    "    master_df = pd.concat([master_df, transposed_df], ignore_index=True)\n",
    "    GEN_df = pd.concat([GEN_df, GEN_result], ignore_index=True)\n",
    "    SHUT_df = pd.concat([SHUT_df, SHUT_result], ignore_index=True)\n",
    "    START_df = pd.concat([START_df, START_result], ignore_index=True)\n",
    "    master_shut_df = pd.concat([master_shut_df, shut_df], ignore_index=True)\n",
    "    master_commit = pd.concat([master_commit, commit_result], ignore_index=True)\n",
    "    master_kinfTable = pd.concat([master_kinfTable, kinfTable_udt], ignore_index=True)\n",
    "\n",
    "    # Save checkpoint after each run\n",
    "    save_checkpoint(n-1, start_day, checkpoint_dir,\n",
    "                master_df, GEN_df, SHUT_df, START_df,\n",
    "                master_shut_df, master_commit, master_kinfTable)\n",
    "\n",
    "# Save final results in formatted output\n",
    "os.remove(f'kinfTable_udt_{end_day+1}.csv')\n",
    "os.remove(f'terminate_loop_indicator_{end_day+1}.csv')\n",
    "os.remove(f'remaining_downtime_{end_day+1}.csv')\n",
    "os.remove(f'commit_at_len_T_{end_day+1}.csv')\n",
    "os.remove(f'D_points_{end_day+1}.csv')\n",
    "\n",
    "today = datetime.now().strftime(\"%Y-%m-%d_%H-%M\")\n",
    "resource = kinfTable_udt['resource'].iloc[0]\n",
    "# subfolder_name = f\"datetime_{today}_startday_{start_day}_endday_{end_day}_{resource}\"\n",
    "# subfolder_name = subfolder_name\n",
    "results_path = os.path.join('results', subfolder_name)\n",
    "os.makedirs(results_path, exist_ok=True)\n",
    "\n",
    "master_df.to_csv(os.path.join(results_path, 'aggregate_results.csv'))\n",
    "GEN_df.to_csv(os.path.join(results_path, 'GEN_results.csv'))\n",
    "SHUT_df.to_csv(os.path.join(results_path, 'SHUT_results.csv'))\n",
    "START_df.to_csv(os.path.join(results_path, 'START_results.csv'))\n",
    "master_shut_df.to_csv(os.path.join(results_path, 'shut_count_and_obj_value.csv'))\n",
    "master_commit.to_csv(os.path.join(results_path, 'COMMIT_results.csv'))\n",
    "master_kinfTable.to_csv(os.path.join(results_path, 'master_kinfTable.csv'))\n",
    "\n",
    "log_file_path = os.path.join(results_path, 'run_log.txt')\n",
    "\n",
    "with open(log_file_path, 'w') as file:\n",
    "    for detail in run_details:\n",
    "        info_text = f\"\"\"\n",
    "        Day: {detail['Day']}\n",
    "        Horizon: {detail['Horizon']} hours\n",
    "        Load Percentage: {detail['Load Percentage']*100}%\n",
    "        PHS Percentage: {detail['PHS Percentage']*100}%\n",
    "        PHS Duration: {detail['PHS Duration']} hours\n",
    "        Nuclear Unit: {detail['Nuclear Unit']}\n",
    "        Model Name: {detail['Model Name']}\n",
    "        Solar Capacity: {detail['Solar Cap']}\n",
    "        Wind Capacity: {detail['Wind Cap']}\n",
    "        Date of Run: {detail['Date of Run']}\n",
    "        \"\"\"\n",
    "        file.write(info_text)\n",
    "        file.write(\"\\n\" + \"-\"*60 + \"\\n\")\n",
    "    file.write(\"End of run log.\\n\")\n",
    "\n",
    "\n",
    "print(\"Finished runs!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
